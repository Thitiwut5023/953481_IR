{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "We are importing the following libraries:\n",
    "- **pandas**: Used for data manipulation and analysis, especially with dataframes.\n",
    "- **numpy**: Provides tools for numerical computations, including arrays and mathematical operations.\n",
    "- **string**: Contains a collection of string constants and functions useful for string manipulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T14:36:41.372496Z",
     "start_time": "2024-12-03T14:36:40.415431Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Tokenization\n",
    "\n",
    "1. **`get_and_clean_data`**: \n",
    "   - Reads data from a CSV file.\n",
    "   - Cleans the data (removes NaN, strips punctuation except `#` and `+`, converts to lowercase, normalizes whitespace).\n",
    "   - Removes duplicate rows.\n",
    "\n",
    "2. **`simple_tokenize`**: \n",
    "   - Tokenizes text in `job_title` and `job_description` into individual words.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T14:36:41.387327Z",
     "start_time": "2024-12-03T14:36:41.374518Z"
    }
   },
   "source": [
    "# Define the columns to filter from the dataset\n",
    "filters = ['job_title', 'job_description']\n",
    "\n",
    "# Function to load and clean the dataset\n",
    "def get_and_clean_data():\n",
    "    # Load dataset from a CSV file\n",
    "    data = pd.read_csv('data/software_developer_united_states_1971_20191023_1.csv')\n",
    "    \n",
    "    # Keep only the specified columns (filters)\n",
    "    filtered_data = data[filters]\n",
    "    \n",
    "    # Iterate through each column in the filters\n",
    "    for column in filters:\n",
    "        # Replace NaN values with an empty string\n",
    "        filtered_data[column] = filtered_data[column].fillna('')\n",
    "        \n",
    "        # Remove punctuation except '#' and '+'\n",
    "        filtered_data[column] = filtered_data[column].apply(\n",
    "            lambda s: s.translate(\n",
    "                str.maketrans('', '', string.punctuation.replace('#', '').replace('+', ''))\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Convert text to lowercase\n",
    "        filtered_data[column] = filtered_data[column].apply(lambda s: s.lower())\n",
    "        \n",
    "        # Normalize whitespace characters\n",
    "        filtered_data[column] = filtered_data[column].apply(\n",
    "            lambda s: s.translate(str.maketrans(string.whitespace, ' ' * len(string.whitespace), ''))\n",
    "        )\n",
    "    \n",
    "    # Remove duplicate rows\n",
    "    filtered_data = filtered_data.drop_duplicates()\n",
    "    \n",
    "    # Return the cleaned dataset\n",
    "    return filtered_data\n",
    "\n",
    "# Function to tokenize text in each column of the dataset\n",
    "def simple_tokenize(data):\n",
    "    for column in filters:\n",
    "        # Split text into tokens and strip whitespace from each token\n",
    "        data[column] = data[column].apply(lambda s: [x.strip() for x in s.split()])\n",
    "    return data\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Cleaned and Tokenized Data\n",
    "- Cleans and tokenizes the dataset using the defined functions.\n",
    "- Displays the first 10 rows in markdown table format for easy visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T14:36:49.437870Z",
     "start_time": "2024-12-03T14:36:42.015135Z"
    }
   },
   "source": [
    "# Clean and tokenize data\n",
    "data = get_and_clean_data()\n",
    "data = simple_tokenize(data)\n",
    "\n",
    "# Display the first 10 rows\n",
    "print(data.head(10))\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_30056\\2774603895.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[column] = filtered_data[column].fillna('')\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_30056\\2774603895.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[column] = filtered_data[column].apply(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_30056\\2774603895.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[column] = filtered_data[column].apply(lambda s: s.lower())\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_30056\\2774603895.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[column] = filtered_data[column].apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     job_title  \\\n",
      "0                    [sr, software, developer]   \n",
      "1              [c#, lead, software, developer]   \n",
      "2                [senior, software, developer]   \n",
      "3                [senior, software, developer]   \n",
      "4              [c#, lead, software, developer]   \n",
      "5                     [software, developer, 3]   \n",
      "6                   [c++, software, developer]   \n",
      "7  [c++, software, developer, local, w2, only]   \n",
      "8                   [software, developer, net]   \n",
      "9                   [net, software, developer]   \n",
      "\n",
      "                                     job_description  \n",
      "0  [the, chosen, sr, software, developer, will, b...  \n",
      "1  [position, c#, lead, software, developer, loca...  \n",
      "2  [senior, software, developer, hoboken, nj, sta...  \n",
      "3  [our, client, a, multinational, publishing, an...  \n",
      "4  [position, c#, lead, software, developer, loca...  \n",
      "5  [responsibilities, kforce, has, a, client, see...  \n",
      "6  [apply, by, emaildirect, application, at, udit...  \n",
      "7  [talent, space, inc, is, looking, for, c++, so...  \n",
      "8  [primary, purpose, development, and, maintenan...  \n",
      "9  [ref, id, 027600010838185, classification, sof...  \n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter for Junior Roles\n",
    "- Filters the dataset for job titles containing \"junior\" or \"jr\".\n",
    "- Displays the total count and the first 10 rows of filtered results in markdown table format.\n",
    "\n",
    "### Q1: Identify database and programming language proficiencies essential for a junior-level (2pts, should be achievable by everyone)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T14:36:49.562030Z",
     "start_time": "2024-12-03T14:36:49.538490Z"
    }
   },
   "source": [
    "# Filter rows where 'junior' or 'jr' is mentioned in the job title\n",
    "junior_roles = data[data['job_title'].apply(lambda tokens: 'junior' in tokens or 'jr' in tokens)]\n",
    "\n",
    "# Display the count of filtered jobs and the first 10 rows\n",
    "print(f'Job counts = {len(junior_roles)}')\n",
    "print(junior_roles.head(10))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job counts = 513\n",
      "                                             job_title  \\\n",
      "20                       [junior, software, developer]   \n",
      "40                       [junior, software, developer]   \n",
      "46                           [jr, software, developer]   \n",
      "52                       [junior, software, developer]   \n",
      "68   [junior, to, mid, level, software, developer, ...   \n",
      "90   [junior, level, software, developer, 14, years...   \n",
      "163  [junior, software, developer, engineer, in, te...   \n",
      "178                  [junior, c#, software, developer]   \n",
      "183                      [junior, software, developer]   \n",
      "197                      [junior, software, developer]   \n",
      "\n",
      "                                       job_description  \n",
      "20   [about, harmer, consultants, inc, harmer, cons...  \n",
      "40   [responsibilities, kforce, has, a, client, see...  \n",
      "46   [jr, software, developer, about, acet, adams, ...  \n",
      "52   [responsibilities, kforce, has, a, client, see...  \n",
      "68   [general, dynamics, information, technology, a...  \n",
      "90   [a, fulltime, position, at, a, financial, tech...  \n",
      "163  [description, the, information, technology, qu...  \n",
      "178  [ref, id, 009000010840340, classification, sof...  \n",
      "183  [minimum, required, skills, python, java, java...  \n",
      "197  [idexcel, is, looking, for, junior, java, deve...  \n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Languages Analysis\n",
    "- Counts mentions of specific programming languages in the `job_description` column.\n",
    "- Sorts the languages by frequency in descending order.\n",
    "- Displays the ranked list of programming languages with their counts.\n",
    "\n",
    "### This one we compare the languages and count the frequency"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T14:36:49.704326Z",
     "start_time": "2024-12-03T14:36:49.643416Z"
    }
   },
   "source": [
    "# List of programming languages to count in job descriptions\n",
    "program_languages = ['c', 'c#', 'c++', 'java', 'python', 'kotlin', 'swift', 'rust', 'ruby', 'scala', 'julia', 'lua']\n",
    "\n",
    "# Initialize a dictionary to store counts for each language\n",
    "languages_counter = {}\n",
    "\n",
    "for pl in program_languages:\n",
    "    # Count occurrences of each language in job descriptions\n",
    "    count = junior_roles['job_description'].apply(lambda s: pl in s).sum()\n",
    "    languages_counter[pl] = count\n",
    "\n",
    "# Sort the programming languages by count in descending order\n",
    "languages_counter = sorted(languages_counter.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the rankings\n",
    "print(\"For programming Languages: \")\n",
    "for lang, count in languages_counter:\n",
    "    print(f' - {lang}: {count}')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For programming Languages: \n",
      " - java: 270\n",
      " - c#: 194\n",
      " - c++: 129\n",
      " - python: 88\n",
      " - c: 75\n",
      " - ruby: 73\n",
      " - swift: 10\n",
      " - scala: 5\n",
      " - kotlin: 0\n",
      " - rust: 0\n",
      " - julia: 0\n",
      " - lua: 0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database and Cloud Service Analysis\n",
    "- Counts mentions of specific databases and cloud services in the `job_description` column.\n",
    "- Sorts the results by frequency in descending order.\n",
    "- Displays the ranked list of databases and cloud services with their counts.\n",
    "\n",
    "### And this one is for data base"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T14:36:49.812320Z",
     "start_time": "2024-12-03T14:36:49.743304Z"
    }
   },
   "source": [
    "# List of databases and cloud services to analyze\n",
    "databases = ['mysql', 'postgresql', 'mssql', 'oracle', 'sqlite', \n",
    "             'mongodb', 'cassandra', 'redis', 'dynamodb', 'firebase', \n",
    "             'neo4j', 'cloudsql', 'aws', 'azure', 'bigquery']\n",
    "\n",
    "# Initialize a dictionary to store counts for each database\n",
    "databases_counter = {}\n",
    "\n",
    "for db in databases:\n",
    "    # Count occurrences of each database in job descriptions\n",
    "    count = junior_roles['job_description'].apply(lambda s: db in s).sum()\n",
    "    databases_counter[db] = count\n",
    "\n",
    "# Sort the databases by count in descending order\n",
    "databases_counter = sorted(databases_counter.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the rankings\n",
    "print(\"For databases: \")\n",
    "for db, count in databases_counter:\n",
    "    print(f' - {db}: {count}')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For databases: \n",
      " - oracle: 101\n",
      " - mysql: 86\n",
      " - aws: 34\n",
      " - azure: 19\n",
      " - mssql: 11\n",
      " - postgresql: 10\n",
      " - mongodb: 8\n",
      " - sqlite: 3\n",
      " - cassandra: 3\n",
      " - redis: 3\n",
      " - dynamodb: 2\n",
      " - neo4j: 1\n",
      " - firebase: 0\n",
      " - cloudsql: 0\n",
      " - bigquery: 0\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### So the answer of question 1 is top languages is java and the database is oracle"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2: For a long-term skill development plan, determine an additional programming language to complement your initial choice for a first job. (2 pts – achievable with extra effort)\n",
    "Hints:\n",
    "- Analyze effective pairings between your selected language and one another programming language at time.\n",
    "- Focus only on senior-level role.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T14:36:49.844765Z",
     "start_time": "2024-12-03T14:36:49.827506Z"
    }
   },
   "source": [
    "# Filter rows where 'senior' or 'sr' is mentioned in the job title\n",
    "senior_roles = data[data['job_title'].apply(lambda tokens: 'senior' in tokens or 'sr' in tokens)]\n",
    "\n",
    "# Display the count of filtered jobs and the first 10 rows\n",
    "print(f'Job counts = {len(senior_roles)}')\n",
    "print(senior_roles.head(10))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job counts = 1583\n",
      "                                     job_title  \\\n",
      "0                    [sr, software, developer]   \n",
      "2                [senior, software, developer]   \n",
      "3                [senior, software, developer]   \n",
      "10         [senior, java, software, developer]   \n",
      "15               [senior, software, developer]   \n",
      "23               [software, developer, senior]   \n",
      "25               [senior, software, developer]   \n",
      "26  [senior, full, stack, software, developer]   \n",
      "27          [software, developer, sr, advisor]   \n",
      "35                   [sr, software, developer]   \n",
      "\n",
      "                                      job_description  \n",
      "0   [the, chosen, sr, software, developer, will, b...  \n",
      "2   [senior, software, developer, hoboken, nj, sta...  \n",
      "3   [our, client, a, multinational, publishing, an...  \n",
      "10  [job, summary, biotelemetry, provides, realtim...  \n",
      "15  [minimum, required, skills, net, c#, visual, s...  \n",
      "23  [read, what, people, are, saying, about, worki...  \n",
      "25  [the, denzel, group, has, been, chosen, to, wo...  \n",
      "26  [we, are, hiring, a, senior, full, stack, deve...  \n",
      "27  [read, what, people, are, saying, about, worki...  \n",
      "35  [job, summary, randstad, technologies, is, loo...  \n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T14:36:49.919714Z",
     "start_time": "2024-12-03T14:36:49.890490Z"
    }
   },
   "source": [
    "# Filter senior roles by the most mentioned programming language (from the previous ranking)\n",
    "top_senior_roles = senior_roles[senior_roles['job_description'].apply(lambda tokens: languages_counter[0][0] in tokens)]\n",
    "\n",
    "# Display the count of filtered senior roles and the first 10 rows\n",
    "print(f'Job counts = {len(top_senior_roles)}, filtered by {languages_counter[0][0]}')\n",
    "print(top_senior_roles.head(10))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job counts = 706, filtered by java\n",
      "                                            job_title  \\\n",
      "10                [senior, java, software, developer]   \n",
      "23                      [software, developer, senior]   \n",
      "27                 [software, developer, sr, advisor]   \n",
      "38                    [sr, lead, software, developer]   \n",
      "44  [senior, java, software, developerengineer, im...   \n",
      "51        [sr, software, developer, java, cloud, api]   \n",
      "57                    [sr, java, software, developer]   \n",
      "67                 [sr, steppim, software, developer]   \n",
      "81  [software, developer, analyst, ii, or, senior,...   \n",
      "93    [senior, frontend, software, developer, remote]   \n",
      "\n",
      "                                      job_description  \n",
      "10  [job, summary, biotelemetry, provides, realtim...  \n",
      "23  [read, what, people, are, saying, about, worki...  \n",
      "27  [read, what, people, are, saying, about, worki...  \n",
      "38  [employer, nyse, ctl, is, a, global, communica...  \n",
      "44  [position, overview, java, software, developer...  \n",
      "51  [our, client, is, seeking, a, senior, software...  \n",
      "57  [read, what, people, are, saying, about, worki...  \n",
      "67  [our, client, is, currently, seeking, a, sr, s...  \n",
      "81  [read, what, people, are, saying, about, worki...  \n",
      "93  [job, description, overview, if, you, are, pas...  \n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Count the filtered data again"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T14:36:50.044958Z",
     "start_time": "2024-12-03T14:36:49.962853Z"
    }
   },
   "source": [
    "# Remove the top programming language (most mentioned) from the list\n",
    "program_languages.remove(languages_counter[0][0])\n",
    "\n",
    "# Initialize a dictionary to store co-occurrence counts for remaining languages\n",
    "co_occurrence_counts = {}\n",
    "\n",
    "for pl in program_languages:\n",
    "    # Count occurrences of each remaining language in the job descriptions of top senior roles\n",
    "    count = top_senior_roles['job_description'].apply(lambda tokens: pl in tokens).sum()\n",
    "    co_occurrence_counts[pl] = count\n",
    "\n",
    "# Sort the co-occurrence counts in descending order\n",
    "co_occurrence_counts = sorted(co_occurrence_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the co-occurrence counts for the remaining languages\n",
    "print(f'Co-occurrence of programming languages with {languages_counter[0][0]}:')\n",
    "for lang, count in co_occurrence_counts:\n",
    "    print(f\" - {lang}: {count}\")\n",
    "\n",
    "# Identify the most co-occurring programming language\n",
    "additional_programming_language = co_occurrence_counts[0][0]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co-occurrence of programming languages with java:\n",
      " - c#: 217\n",
      " - python: 149\n",
      " - c++: 98\n",
      " - c: 73\n",
      " - ruby: 45\n",
      " - scala: 25\n",
      " - swift: 16\n",
      " - kotlin: 11\n",
      " - lua: 1\n",
      " - rust: 0\n",
      " - julia: 0\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Answer of question 2 is c# (217)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question3:Design and execute an experiment that determines which database proefficiency is best suited for a senior software developer role. (1pt – challenging assignment)\n",
    "\n",
    "- Apply Bayes' theorem and code the formula to support your analysis.<br>\n",
    "- Use Monte Carlo simulations with 10,000 iterations to demonstrate your conclusions.<br>\n",
    "- Hint: P(senior software developer) is around 7% and you already know each P(skill) already. You will need to assume and code their distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Bayes Theorem\n",
    "\n",
    "#### Probability Calculations\n",
    "1. **P(senior)**: Calculates the probability of a job being a senior role in the dataset.\n",
    "2. **P(skill)**: Calculates the probability of each skill (database) appearing in all job descriptions.\n",
    "3. **P(skill | senior)**: Calculates the probability of each skill (database) appearing in senior roles.\n",
    "\n",
    "Displays the probabilities for:\n",
    "- **P(senior)**\n",
    "- **P(skill)**\n",
    "- **P(skill | senior)**\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T14:36:51.175200Z",
     "start_time": "2024-12-03T14:36:50.070241Z"
    }
   },
   "source": [
    "# P(senior)\n",
    "P_senior = len(senior_roles) / len(data)\n",
    "\n",
    "# Calculate P(skill) and P(skill | senior)\n",
    "P_skill = {}\n",
    "P_skill_given_senior = {}\n",
    "\n",
    "for db in databases:\n",
    "    # P(skill): All jobs mentioning the skill\n",
    "    P_skill[db] = data['job_description'].apply(lambda s: db in s).sum() / len(data)\n",
    "    \n",
    "    # P(skill | senior): Senior jobs mentioning the skill\n",
    "    P_skill_given_senior[db] = senior_roles['job_description'].apply(lambda s: db in s).sum() / len(senior_roles)\n",
    "\n",
    "print(\"P(senior):\", P_senior)\n",
    "print(\"P(skill):\", P_skill)\n",
    "print(\"P(skill | senior):\", P_skill_given_senior)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(senior): 0.2075793338578547\n",
      "P(skill): {'mysql': 0.08785733018620509, 'postgresql': 0.03448728035667453, 'mssql': 0.014424337791765015, 'oracle': 0.18345135064253867, 'sqlite': 0.0036716496197220037, 'mongodb': 0.03920797272488854, 'cassandra': 0.01888276947285602, 'redis': 0.014030946761080514, 'dynamodb': 0.011670600576973512, 'firebase': 0.0013113034356150013, 'neo4j': 0.0036716496197220037, 'cloudsql': 0.00026226068712300026, 'aws': 0.13335955940204564, 'azure': 0.07802255441909257, 'bigquery': 0.0005245213742460005}\n",
      "P(skill | senior): {'mysql': 0.07770056854074542, 'postgresql': 0.028427037271004423, 'mssql': 0.007580543272267846, 'oracle': 0.1945672773215414, 'sqlite': 0.006317119393556538, 'mongodb': 0.04611497157296273, 'cassandra': 0.02021478205938092, 'redis': 0.02147820593809223, 'dynamodb': 0.013265950726468731, 'firebase': 0.0012634238787113076, 'neo4j': 0.005685407454200884, 'cloudsql': 0.0, 'aws': 0.20025268477574226, 'azure': 0.09665192672141504, 'bigquery': 0.0}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Calulate with bayes theorem"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T14:36:51.210626Z",
     "start_time": "2024-12-03T14:36:51.199770Z"
    }
   },
   "source": [
    "P_senior_given_skill = {}\n",
    "\n",
    "for db in databases:\n",
    "    if P_skill[db] > 0:  # Avoid division by zero\n",
    "        P_senior_given_skill[db] = (P_skill_given_senior[db] * P_senior) / P_skill[db]\n",
    "    else:\n",
    "        P_senior_given_skill[db] = 0\n",
    "\n",
    "# Display results\n",
    "sorted_probs = sorted(P_senior_given_skill.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"P(senior | skill) Ranking:\")\n",
    "for db, prob in sorted_probs:\n",
    "    print(f\" - {db}: {prob:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(senior | skill) Ranking:\n",
      " - sqlite: 0.3571\n",
      " - neo4j: 0.3214\n",
      " - redis: 0.3178\n",
      " - aws: 0.3117\n",
      " - azure: 0.2571\n",
      " - mongodb: 0.2441\n",
      " - dynamodb: 0.2360\n",
      " - cassandra: 0.2222\n",
      " - oracle: 0.2202\n",
      " - firebase: 0.2000\n",
      " - mysql: 0.1836\n",
      " - postgresql: 0.1711\n",
      " - mssql: 0.1091\n",
      " - cloudsql: 0.0000\n",
      " - bigquery: 0.0000\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo Simulation for Senior Role Probabilities\n",
    "- Runs **Monte Carlo simulations** (10,000 iterations) to estimate the probability of a senior role given a skill.\n",
    "- Simulates the occurrence of a skill and a senior role using binomial distributions based on **P(skill)** and **P(senior)**.\n",
    "- Applies **Bayes' Theorem** to compute the conditional probability **P(senior | skill)**.\n",
    "- Displays the average results for each database and ranks them by the highest probability.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T14:36:51.573764Z",
     "start_time": "2024-12-03T14:36:51.249288Z"
    }
   },
   "source": [
    "# Number of Monte Carlo iterations\n",
    "iterations = 10000\n",
    "\n",
    "# Initialize dictionary to store results for each database\n",
    "monte_carlo_results = {db: [] for db in databases}\n",
    "\n",
    "# Run Monte Carlo simulations\n",
    "for db in databases:\n",
    "    for _ in range(iterations):\n",
    "        # Simulate skill occurrence based on P(skill) using binomial distribution\n",
    "        skill_occurrence = np.random.binomial(1, P_skill[db])\n",
    "        \n",
    "        # Simulate senior role occurrence based on P(senior) using binomial distribution\n",
    "        senior_occurrence = np.random.binomial(1, P_senior)\n",
    "        \n",
    "        if skill_occurrence and senior_occurrence:\n",
    "            # Apply Bayes' Theorem to calculate P(senior | skill)\n",
    "            P_senior_given_skill = (P_skill_given_senior[db] * P_senior) / P_skill[db]\n",
    "            monte_carlo_results[db].append(P_senior_given_skill)\n",
    "\n",
    "# Calculate average results from the Monte Carlo simulations\n",
    "average_results = {db: np.mean(monte_carlo_results[db]) for db in databases}\n",
    "\n",
    "# Sort results and display the rankings\n",
    "sorted_monte_carlo = sorted(average_results.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Monte Carlo Simulation Rankings:\")\n",
    "for db, prob in sorted_monte_carlo:\n",
    "    print(f\" - {db}: {prob:.4f}\")\n",
    "\n",
    "# Identify the top-ranked database\n",
    "top_sim = sorted_monte_carlo[0]\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monte Carlo Simulation Rankings:\n",
      " - sqlite: 0.3571\n",
      " - neo4j: 0.3214\n",
      " - redis: 0.3178\n",
      " - cloudsql: nan\n",
      " - aws: 0.3117\n",
      " - azure: 0.2571\n",
      " - mongodb: 0.2441\n",
      " - dynamodb: 0.2360\n",
      " - cassandra: 0.2222\n",
      " - oracle: 0.2202\n",
      " - firebase: 0.2000\n",
      " - mysql: 0.1836\n",
      " - postgresql: 0.1711\n",
      " - mssql: 0.1091\n",
      " - bigquery: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\new\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\new\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### **Answer question 3:**  sqlite the top from simulation has the highest posterior probability"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se_411",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
